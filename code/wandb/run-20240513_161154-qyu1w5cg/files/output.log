  0%|                                                                                                                                                                                                                                                                     | 0/100 [00:00<?, ?it/s]/home/icl2/anaconda3/lib/python3.10/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(



  5%|████████████▌                                                                                                                                                                                                                                              | 5/100 [03:23<1:04:21, 40.65s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (93 > 77). Running this sequence through the model will result in indexing errors
The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['morbacher, female, feminine, art deco, new baroque, intricate linework']
The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['morbacher, female, feminine, art deco, new baroque, intricate linework']























 30%|███████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                | 30/100 [20:19<47:26, 40.67s/it]The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', tom bagshaw, lawrence alma - tadema, greg rutkowski, alphonse mucha']
The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', tom bagshaw, lawrence alma - tadema, greg rutkowski, alphonse mucha']























 55%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                 | 55/100 [37:17<30:44, 40.99s/it]The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['germ and greg rutkowski and alphonse mucha and loish and wlop']
The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['germ and greg rutkowski and alphonse mucha and loish and wlop']



 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                    | 60/100 [40:44<27:29, 41.25s/it]The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['new yorker magazine cover']
The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['new yorker magazine cover']
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                    | 60/100 [41:19<27:32, 41.32s/it]
Traceback (most recent call last):
  File "/home/icl2/khlee/InstaFlow/code/main_new_algorithm.py", line 295, in <module>
    main()
  File "/home/icl2/khlee/InstaFlow/code/main_new_algorithm.py", line 212, in main
    original_image, recon_image, diff_image, original_latents_visualized, recon_latents_visualized, diff_latents_visualized, error_TOT, error_OTO, error_middle, output_loss, peak_gpu_allocated, inf_time, inv_time, seed, extra_outputs, extra_outputs_another, another_output = single_exp(seed, prompt, inversion_prompt,
  File "/home/icl2/anaconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/icl2/khlee/InstaFlow/code/main_new_algorithm.py", line 48, in single_exp
    recon_images, recon_zo, recon_latents, output_loss, peak_gpu_allocated, dec_inv_time, extra_outputs, extra_outputs_another, another_output = insta_pipe.exact_inversion(
  File "/home/icl2/khlee/InstaFlow/code/pipeline_rf.py", line 955, in exact_inversion
    latents, extra_outputs, extra_outputs_another, another_output = self.dec_direct(image, latents, test_beta=test_beta, adam=False, decoder_inv_steps=decoder_inv_steps, decoder_lr=decoder_lr, verbose=verbose, use_float=decoder_use_float)
  File "/home/icl2/anaconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/icl2/khlee/InstaFlow/code/pipeline_rf.py", line 1489, in dec_direct
    cocoercivity_rate_array_another[i] = cocoercivity_rate
KeyboardInterrupt